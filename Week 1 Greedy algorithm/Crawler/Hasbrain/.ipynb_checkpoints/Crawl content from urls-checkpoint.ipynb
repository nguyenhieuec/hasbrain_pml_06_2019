{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56f9f70d-9fd6-4cca-9458-54d2798be73f"
   },
   "source": [
    "# Get main content of news\n",
    "\n",
    "To get main content of news, we will use a library called newspaper:\n",
    "\n",
    "Firstly, install the library by running the below code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "085db20b-0fc2-45a8-a1d2-7a2efaf24760"
   },
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/codelucas/newspaper/master/download_corpora.py | python3\n",
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f58eff04-30bf-4588-bcb4-45d0d25f5e13"
   },
   "source": [
    "Import the library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a260188b-f2ef-4882-8c63-6208dad2675c"
   },
   "outputs": [],
   "source": [
    "from newspaper import fulltext\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c93b61f5-45b4-41a9-9f09-e0f82509deb5"
   },
   "source": [
    "Try to get content of the below link by\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0d749af-163d-46a5-93a7-7ce9c183e03d"
   },
   "outputs": [],
   "source": [
    "url = \"https://seekingalpha.com/news/3454711-facebook-broke-privacy-laws-exposing-user-data-canada-says\"\n",
    "html = requests.get(url).text\n",
    "text = fulltext(html)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4c6acbe-dab4-4d85-858d-e6fb902ecbed"
   },
   "source": [
    "It's really easy, isn't it? However, when you crawl thousands of articles, the\n",
    "\n",
    "# Adding proxies\n",
    "\n",
    "The purpose of adding proxies to the request is to get the content indirectly via other IPs. You will change the proxy in each time you call request, the seekingalpha will be not able to detect and ban your IP anymore.\n",
    "\n",
    "## Getting proxies\n",
    "\n",
    "How can we get the list of free proxies?\n",
    "\n",
    "To get the list of proxies, we need to get the html of the page and parse it with BeautifulSoup library. Firstly, let's install and import essential libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4cd5ac4-7d39-4a4b-a227-39e3db6689bc"
   },
   "outputs": [],
   "source": [
    "# !pip install lxml\n",
    "import random\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4d9edbaa-302f-4800-9852-0a64532a6dfa"
   },
   "source": [
    "The following function retrieves a list of proxies, please finish it by following instructions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7f940f2b-76c1-436d-af81-ad9ea7447660"
   },
   "outputs": [],
   "source": [
    "def get_proxies():\n",
    "### START CODE HERE\n",
    "# Create a GET request with url is https://free-proxy-list.net/\n",
    "# and header User-Agent: Mozilla/5.0\n",
    "    res = requests.get('https://free-proxy-list.net/', headers={'User-Agent':'Mozilla/5.0'})\n",
    "\n",
    "    # Create a BeautifilSoup object with html from 'res'\n",
    "    # and using 'lxml' as HTML parser\n",
    "    soup = BeautifulSoup(res.text,\"lxml\")\n",
    "\n",
    "    proxies = []\n",
    "\n",
    "    # Get all rows by select \"tbody tr\"\n",
    "    rows = soup.select(\"tbody tr\")\n",
    "    for row in rows:\n",
    "    # Select all row values by \"td\"\n",
    "        values = row.select(\"td\")\n",
    "        # Build the proxy with the syntax <values[0].text>:<values[1].text>\n",
    "        # then append to 'proxies'\n",
    "        proxy = values[0].text + \":\" + values[1].text\n",
    "        proxies.append(proxy)\n",
    "\n",
    "    ### END CODE HERE\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9d20a1f1-6497-4dbb-a811-1affcb67ae0c"
   },
   "source": [
    "Try getting the list of proxies with the above function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "242dfff5-2552-40b5-bb5d-98fd158d5128"
   },
   "outputs": [],
   "source": [
    "get_proxies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "687d74d7-7bb4-4934-a09b-4bf76d1a2ae7"
   },
   "source": [
    "## Adding proxies to request\n",
    "\n",
    "After getting the list of proxies, we will pick a random proxy and add it to the request we call:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "380ad264-41a8-4fa6-861f-6dcff3a78135"
   },
   "outputs": [],
   "source": [
    "# Url to get content\n",
    "url = \"https://seekingalpha.com/news/3454711-facebook-broke-privacy-laws-exposing-user-data-canada-says\"\n",
    "# Get list of proxies\n",
    "proxies = get_proxies()\n",
    "# Pick a random proxy\n",
    "proxy = proxies[random.randint(0, len(proxies)-1)]\n",
    "# Build proxy dictionary\n",
    "proxy_dict = {\n",
    "\"http\": \"http://\"+proxy,\n",
    "\"https\": \"https://\"+proxy\n",
    "}\n",
    "# Request with proxy\n",
    "html = requests.get(url, headers={'User-Agent':'Mozilla/5.0'}, proxies=proxy_dict).text\n",
    "text = fulltext(html)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5de91c02-bb9e-4ee6-9fc3-9add6ae3c602"
   },
   "source": [
    "The proxies we got are all free, so it will not be stable (it usually throws error), we need to check the status of request to know whether it's success or not. When it get the status 200 like the below example, the request is success, otherwise you need to retry with another proxy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eec146a-dcb6-4515-8922-28eae6e9032a"
   },
   "outputs": [],
   "source": [
    "requests.get(url, headers={'User-Agent':'Mozilla/5.0'}).status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6a80a193-e783-457d-9b16-c06409bc5251"
   },
   "source": [
    "Besides, we should not use the same proxy list for all of your requests, we will check and request new proxies every 2 minutes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0dad2608-ca14-4c22-8436-8ce59797ff11"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "last_request_time = datetime.now()\n",
    "current_proxies = []\n",
    "def get_current_proxies():\n",
    "    global last_request_time, current_proxies\n",
    "    # If last request is in the last 2 minutes, do not request proxy list\n",
    "    if (datetime.now() - last_request_time).seconds < 120 and len(current_proxies) > 0:\n",
    "        return current_proxies\n",
    "    # Get new proxy list\n",
    "    current_proxies = get_proxies()\n",
    "    last_request_time = datetime.now()\n",
    "    return current_proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-20-78bf7a6c0ca6>\", line 1, in <module>\n",
      "    cmd = \"enerCHARMM.pl -par param=x,xtop=topology_modified.rtf,xpar=lipid27_modified.par,nobuildall -out vdwaals {0}\".format(cmtup[1])\n",
      "NameError: name 'cmtup' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/hieunguyen/anaconda3/lib/python3.6/posixpath.py\", line 376, in abspath\n",
      "    cwd = os.getcwd()\n",
      "OSError: [Errno 24] Too many open files\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cmtup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02a3053f-c0bc-4d0a-8274-41531b76fc8f"
   },
   "source": [
    "The next function receives a url and return the content of this url. Following the below instruction, complete the function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "986add85-b414-4e9e-a71d-57407c9cc287"
   },
   "outputs": [],
   "source": [
    "from urllib3.exceptions import ProxyError as ProxyError\n",
    "from urllib3.exceptions import NewConnectionError\n",
    "# from urllib3.exceptions import MissingSchema as MissingSchemaError\n",
    "from urllib3.exceptions import HTTPError as BaseHTTPError\n",
    "def get_content_from_url(url):\n",
    "    global no_crawled_content\n",
    "    global no_err\n",
    "    global url_err\n",
    "    url_err = []\n",
    "    ### START CODE HERE\n",
    "    # Repeat until getting content\n",
    "    while True:\n",
    "    # Get list of proxies\n",
    "        proxies = get_current_proxies()\n",
    "        # Pick a random proxy and build proxy dictionary\n",
    "        proxy = proxies[random.randint(0, len(proxies)-1)]\n",
    "        proxy_dict = {\n",
    "             \"http\": \"http://\"+proxy,\n",
    "        }\n",
    "        # Request 'url' with proxy (Should catch error when you request)\n",
    "        try:\n",
    "            response = requests.get(url, headers={'User-Agent':'Mozilla/5.0'}, proxies=proxy_dict)\n",
    "        except (ProxyError, NewConnectionError, ConnectionError, requests.ConnectionError, BaseHTTPError.MissingSchema) as e:\n",
    "            no_err += 1\n",
    "            print(no_err, \". Error\", url)\n",
    "            url_err.append(url)\n",
    "            print(\"Cannot connect to proxy\", proxy)\n",
    "            print(e.args)\n",
    "            continue\n",
    "        # Check whether response status code is 200\n",
    "        if response.status_code == 200:\n",
    "        # Parse content from response html\n",
    "            no_crawled_content += 1\n",
    "            print(no_crawled_content, \". Crawled\", url)\n",
    "            return url, fulltext(response.text)\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c1dfcd00-a561-434d-bc70-4edeeefc2127"
   },
   "source": [
    "Test the function with the code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27aff095-f1ec-4d05-b920-24600ac2e52d"
   },
   "outputs": [],
   "source": [
    "no_crawled_content = 0\n",
    "get_content_from_url(\"https://seekingalpha.com/news/3454711-facebook-broke-privacy-laws-exposing-user-data-canada-says\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fba95986-cd43-431a-a04b-121d328cad11"
   },
   "source": [
    "# Crawling content from urls with multi-thread\n",
    "\n",
    "We will use the\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fef22eb1-d9a6-49d4-b6bf-053186b64f59"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset [Seeking Alpha news urls] is mounted\n",
    "and stored in [input/seeking-alpha-news-urls-5cc65ca5cd14d00011a84326] of current machine.\n",
    "\n",
    "Please check your just-mounted dataset by running\n",
    "bellow command:\n",
    "# '''\n",
    "\n",
    "# import os\n",
    "# data_path_326 = \"input/seeking-alpha-news-urls-5cc65ca5cd14d00011a84326\"\n",
    "# # Use \"data_path_326\" as the list of items on this dataset\n",
    "\n",
    "# os.listdir(data_path_326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ebca035-5435-4961-afe7-84bfec5881c0"
   },
   "source": [
    "Get the csv path:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cbcb9ee-1932-4937-9fa8-7beea3281852"
   },
   "outputs": [],
   "source": [
    "# csv_path = os.path.join(data_path_326, 'seeking_alpha.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c649f564-d49c-4218-9e92-0d892c7895c4"
   },
   "source": [
    "Read the list of urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dd68976-4e5d-4c74-866f-95c395fcdbd7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b975a417-1f32-4fd8-ac49-39e8687abd12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>stock</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>url</td>\n",
       "      <td>title</td>\n",
       "      <td>stock</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://seekingalpha.com/news/3467965-google-m...</td>\n",
       "      <td>Google Maps adds popular menu items, GOOGL</td>\n",
       "      <td>1559233807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://seekingalpha.com/news/3467751-google-b...</td>\n",
       "      <td>Google bans apps that facilitate marijuana sal...</td>\n",
       "      <td>1559208044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://seekingalpha.com/news/3467360-google-t...</td>\n",
       "      <td>Google temps outnumber full-time workers - NYT...</td>\n",
       "      <td>1559119152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://seekingalpha.com/news/3466946-google-i...</td>\n",
       "      <td>Google to invest %u20AC600M in Finnish data ce...</td>\n",
       "      <td>1558949797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0                                                url   \n",
       "1  https://seekingalpha.com/news/3467965-google-m...   \n",
       "2  https://seekingalpha.com/news/3467751-google-b...   \n",
       "3  https://seekingalpha.com/news/3467360-google-t...   \n",
       "4  https://seekingalpha.com/news/3466946-google-i...   \n",
       "\n",
       "                                               title        stock   timestamp  \\\n",
       "0                                              title        stock   timestamp   \n",
       "1         Google Maps adds popular menu items, GOOGL   1559233807         NaN   \n",
       "2  Google bans apps that facilitate marijuana sal...   1559208044         NaN   \n",
       "3  Google temps outnumber full-time workers - NYT...   1559119152         NaN   \n",
       "4  Google to invest %u20AC600M in Finnish data ce...   1558949797         NaN   \n",
       "\n",
       "  col5 col6  \n",
       "0  NaN  NaN  \n",
       "1  NaN  NaN  \n",
       "2  NaN  NaN  \n",
       "3  NaN  NaN  \n",
       "4  NaN  NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\"url\", \"title\", \"stock\", \"timestamp\", \"col5\", \"col6\"]\n",
    "\n",
    "url_df = pd.read_csv('googl.csv',escapechar='\\\"', delimiter=',', quoting=csv.QUOTE_NONE, error_bad_lines=False,encoding = 'unicode_escape', names=col_names)\n",
    "url_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "126c1ce9-f643-4359-b036-71898ace7ae8"
   },
   "source": [
    "We will add one more column to the dataframe called\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38220207-0736-4b38-bfaa-2eaf125dea20"
   },
   "outputs": [],
   "source": [
    "\n",
    "pool = ThreadPool(8)\n",
    "results = pool.map(get_content_from_url, [\"https://seekingalpha.com/news/3454711-facebook-broke-privacy-laws-exposing-user-data-canada-says\"])\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59960132-e26b-4722-85fc-8443d9e532b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . Crawled https://seekingalpha.com/news/3435439-youtube-ads-pulled-exploitation-fears\n",
      "2 . Crawled https://seekingalpha.com/news/3432866-apple-increased-autonomous-testing-2018-update3 . Crawled https://seekingalpha.com/news/3451093-alphabet-starts-2019-strong-u-s-spending-otr\n",
      "\n",
      "4 . Crawled https://seekingalpha.com/news/3399537-youtube-ceo-protest-eu-copyright-law\n",
      "5 . Crawled 6 . Crawled https://seekingalpha.com/filing/4330799\n",
      "https://seekingalpha.com/news/3390950-big-google-push-auto-industry\n",
      "7 . Crawled8 . Crawled https://seekingalpha.com/news/3394321-google-gets-new-advertising-chief9 . Crawled https://seekingalpha.com/news/3412271-google-makes-another-silicon-valley-land-grab10 . Crawled https://seekingalpha.com/news/3389132-qualcomm-launches-new-android-watch-processor\n",
      "\n",
      "\n",
      "11 . Crawled https://seekingalpha.com/news/3380302-intercept-google-using-baidu-search-results-re-enter-china https://seekingalpha.com/news/3461815-sap-teams-amazon-google-cloud-project\n",
      "\n",
      "12 . Crawled https://seekingalpha.com/news/3396119-google-files-appeal-5b-eu-fine\n",
      "13 . Crawled https://seekingalpha.com/news/3465759-comcast-working-smart-device-focused-health-cnbc\n",
      "14 . Crawled https://seekingalpha.com/news/3418395-walgreens-verily-partner-cut-health-costs\n",
      "1516 . Crawled https://seekingalpha.com/news/3386001-84-percent-companies-dabbling-blockchain \n",
      ". Crawled17 18 . Crawled . Crawled https://seekingalpha.com/news/3443271-another-eu-fine-hitting-google-next-week\n",
      "https://seekingalpha.com/news/3386980-cnbc-chinese-company-manufactures-googles-titan-key https://seekingalpha.com/news/3395557-sequoia-fund-added-facebook-stake-q3\n",
      "\n",
      "19 . Crawled https://seekingalpha.com/news/3413959-stifel-google-bid-red-hat\n",
      "20 . Crawled https://seekingalpha.com/news/3406292-alphabet-kicks-two-day-health-conference\n",
      "21 . Crawled https://seekingalpha.com/news/3410600-google-cloud-loses-ceo\n",
      "2223 . Crawled https://seekingalpha.com/news/3421537-google-roundup-assistants-busy-ces19\n",
      " . Crawled https://seekingalpha.com/news/3402422-facebook-earnings-put-fangs-focus\n",
      "24 . Crawled https://seekingalpha.com/news/3383585-chicago-tribune-google-planning-first-retail-flagship-store\n",
      "25 . Crawled https://seekingalpha.com/news/3448724-google-shutters-shambolic-ai-board\n",
      "26 . Crawled https://seekingalpha.com/news/3392349-tech-giants-face-commerce-department-hearing-apple-remarks-leak\n",
      "27 . Crawled https://seekingalpha.com/news/3445577-final-vote-eus-controversial-copyright-law\n",
      "28 . Crawled https://seekingalpha.com/news/3416079-google-ceo-testifies-house-committee-updates\n",
      "29 . Crawled https://seekingalpha.com/news/3424436-digital-giants-crosshairs-eu-tax\n",
      "30 31 . Crawled https://seekingalpha.com/filing/4464255\n",
      ". Crawled https://seekingalpha.com/news/3439588-splunk-drops-alphabet-launches-cybersecurity-product\n",
      "32 . Crawled https://seekingalpha.com/news/3427035-dojs-delrahim-watching-facebook-integration-with-interest\n",
      "33 . Crawled https://seekingalpha.com/news/3435415-axios-google-shakes-global-policy-approach\n",
      "34 . Crawled https://seekingalpha.com/news/3388796-google-kb-home-team-put-hardware-new-homes\n",
      "35 . Crawled https://seekingalpha.com/news/3399362-portuguese-app-store-wins-local-court-battle-google\n",
      "36 . Crawled https://seekingalpha.com/news/3432682-google-plans-lower-priced-smartphone-report\n",
      "37 . Crawled https://seekingalpha.com/news/3394175-now-testing-play-assassins-creed-google-chrome\n",
      "38 . Crawled https://seekingalpha.com/news/3412158-baird-sees-alphabet-cloud-m\n",
      "39 . Crawled https://seekingalpha.com/news/3390844-nutanix-minus-10-percent-report-google-plans-private-cloud-offering\n",
      "40 . Crawled https://seekingalpha.com/news/3450904-mid-range-google-pixel-3a-may-coming-t-mobile\n",
      "41 . Crawled https://seekingalpha.com/news/3465755-google-halts-huawei-cut-alongside-u-s-reprieve\n",
      "42 . Crawled https://seekingalpha.com/news/3380193-invesco-qqq-etf-qqq-july-summary\n",
      "43 . Crawled https://seekingalpha.com/news/3396117-eu-privacy-regulators-ready-fine-temporarily-ban-data-offenders\n",
      "44 . Crawled https://seekingalpha.com/news/3460922-googles-music-subscribers-stall-wsj\n",
      "45 . Crawled https://seekingalpha.com/news/3417974-auto-safety-agency-speeds-self-driving-reviews\n",
      "46 . Crawled https://seekingalpha.com/news/3395536-youtube-tv-boosts-cloud-dvr-features-user-feedback\n",
      "47 . Crawled https://seekingalpha.com/news/3442868-u-s-top-general-google-benefits-china-military\n",
      "48 . Crawled https://seekingalpha.com/news/3385839-facing-new-rules-techs-press-federal-privacy-law\n",
      "49 . Crawled https://seekingalpha.com/news/3432539-japan-eyes-tighter-regulations-big-tech\n",
      "50 . Crawled https://seekingalpha.com/news/3465622-alphabet-teams-pfizer-novartis-clinical-trials\n",
      "51 . Crawled https://seekingalpha.com/news/3426528-analyst-google-unlikely-taker-zayo-group\n",
      "5253 . Crawled https://seekingalpha.com/news/3429633-waymo-nearing-deal-renault-nissan-group-bloomberg\n",
      " . Crawled https://seekingalpha.com/news/3450802-google-teases-pixel-3a-may-7\n",
      "54 . Crawled https://seekingalpha.com/news/3465407-google-launches-999-ar-headset\n",
      "55 . Crawled https://seekingalpha.com/news/3390480-cord-cutters-feel-pinch-streaming-costs-gradually-rise\n"
     ]
    }
   ],
   "source": [
    "no_crawled_content = 0\n",
    "pool = ThreadPool(32)\n",
    "results = pool.map(get_content_from_url, list(url_df.url))\n",
    "pool.close() \n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('googlnews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1eda6ebc-0cda-4aa8-ad1f-d0b779bf6e05"
   },
   "source": [
    "The crawling task is quite a bit slow, you can wait up to 24 hours until it finishes crawling all things (~8k articles).\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Crawl content from urls.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
